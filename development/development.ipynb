{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source of data -> https://www.londonair.org.uk/LondonAir/Default.aspx\n",
    "\n",
    "API for hourly returns data in format (see `hourly.json`):\n",
    "```\n",
    "LocalAuthority (Borough)\n",
    "    Site\n",
    "        Species (CO2, NO2)\n",
    "```\n",
    "\n",
    "Not all Boroughs have sites, and generally each site might have a different combination of species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from typing import List, Set, Dict, Tuple, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONF_LOCATIONS = \"locations\"\n",
    "\n",
    "ALL_AUTHORITIES = [\n",
    "     'Barking and Dagenham',\n",
    "     'Barnet',\n",
    "     'Bexley',\n",
    "     'Brent',\n",
    "     'Bromley',\n",
    "     'Camden',\n",
    "     'City of London',\n",
    "     'Croydon',\n",
    "     'Ealing',\n",
    "     'Enfield',\n",
    "     'Greenwich',\n",
    "     'Hackney',\n",
    "     'Hammersmith and Fulham',\n",
    "     'Haringey',\n",
    "     'Harrow',\n",
    "     'Havering',\n",
    "     'Hillingdon',\n",
    "     'Hounslow',\n",
    "     'Islington',\n",
    "     'Kensington and Chelsea',\n",
    "     'Kingston',\n",
    "     'Lambeth',\n",
    "     'Lewisham',\n",
    "     'Merton',\n",
    "     'Newham',\n",
    "     'Redbridge',\n",
    "     'Richmond',\n",
    "     'Southwark',\n",
    "     'Sutton',\n",
    "     'Tower Hamlets',\n",
    "     'Waltham Forest',\n",
    "     'Wandsworth',\n",
    "     'Westminster'\n",
    "]\n",
    "\n",
    "## Use only authorities with data, this might change over time\n",
    "AUTHORITIES = [\n",
    "    \"Barking and Dagenham\",\n",
    "    \"Bexley\",\n",
    "    \"Brent\",\n",
    "    \"Camden\",\n",
    "    \"City of London\",\n",
    "    \"Croydon\",\n",
    "    \"Ealing\",\n",
    "    \"Enfield\",\n",
    "    \"Greenwich\",\n",
    "    \"Hackney\",\n",
    "    \"Haringey\",\n",
    "    \"Harrow\",\n",
    "    \"Havering\",\n",
    "    \"Hillingdon\",\n",
    "    \"Islington\",\n",
    "    \"Kensington and Chelsea\",\n",
    "    \"Kingston\",\n",
    "    \"Lambeth\",\n",
    "    \"Lewisham\",\n",
    "    \"Merton\",\n",
    "    \"Redbridge\",\n",
    "    \"Richmond\",\n",
    "    \"Southwark\",\n",
    "    \"Sutton\",\n",
    "    \"Tower Hamlets\",\n",
    "    \"Wandsworth\",\n",
    "    \"Westminster\",\n",
    "]\n",
    "\n",
    "LAQ_HOURLY_URL = \"http://api.erg.kcl.ac.uk/AirQuality/Hourly/MonitoringIndex/GroupName=London/Json\"\n",
    "\n",
    "TIMEOUT = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTHORITIES = ALL_AUTHORITIES # Check functionality with all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AUTHORITIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper for making the request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_data(url : str, timeout : int = TIMEOUT) -> Dict:\n",
    "    \"\"\"\n",
    "    Request data from a URL and return valid data as dictionary.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=TIMEOUT)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            raise LondonAirQualityException(\n",
    "                f\"Status code {response.status_code} returned from {url}\")\n",
    "\n",
    "    except requests.exceptions.Timeout:\n",
    "        raise LondonAirQualityException(\n",
    "            f\"Request timeout, current timeout is {timeout} seconds\"\n",
    "        )\n",
    "\n",
    "    except requests.exceptions.ConnectionError as exc:\n",
    "        raise LondonAirQualityException(f\"Internet connection error: {exc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the functionality of this package is parsing this raw data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_species(species_data):\n",
    "    \"\"\"Iterate over list of species at each site.\"\"\"\n",
    "    parsed_species_data = []\n",
    "    quality_list = []\n",
    "    for species in species_data:\n",
    "        if species[\"@AirQualityBand\"] != \"No data\":\n",
    "            species_dict = {}\n",
    "            species_dict[\"description\"] = species[\"@SpeciesDescription\"]\n",
    "            species_dict[\"code\"] = species[\"@SpeciesCode\"]\n",
    "            species_dict[\"quality\"] = species[\"@AirQualityBand\"]\n",
    "            species_dict[\"index\"] = species[\"@AirQualityIndex\"]\n",
    "            species_dict[\"summary\"] = (\n",
    "                species_dict[\"code\"] + \" is \" + species_dict[\"quality\"]\n",
    "            )\n",
    "            parsed_species_data.append(species_dict)\n",
    "            quality_list.append(species_dict[\"quality\"])\n",
    "    return parsed_species_data, quality_list\n",
    "\n",
    "\n",
    "def parse_site(entry_sites_data):\n",
    "    \"\"\"Iterate over all sites at an local authority and tidy the data.\"\"\"\n",
    "    authority_data = []\n",
    "    for site in entry_sites_data:\n",
    "        site_data = {}\n",
    "        species_data = []\n",
    "\n",
    "        site_data[\"updated\"] = site[\"@BulletinDate\"]\n",
    "        site_data[\"latitude\"] = site[\"@Latitude\"]\n",
    "        site_data[\"longitude\"] = site[\"@Longitude\"]\n",
    "        site_data[\"site_code\"] = site[\"@SiteCode\"]\n",
    "        site_data[\"site_name\"] = site[\"@SiteName\"].split(\"-\")[-1].lstrip()\n",
    "        site_data[\"site_type\"] = site[\"@SiteType\"]\n",
    "\n",
    "        if isinstance(site[\"Species\"], dict):\n",
    "            species_data = [site[\"Species\"]]\n",
    "        else:\n",
    "            species_data = site[\"Species\"]\n",
    "\n",
    "        parsed_species_data, quality_list = parse_species(species_data)\n",
    "\n",
    "        if not parsed_species_data:\n",
    "            parsed_species_data.append(\"no_species_data\")\n",
    "        site_data[\"pollutants\"] = parsed_species_data\n",
    "\n",
    "        if quality_list:\n",
    "            site_data[\"pollutants_status\"] = max(\n",
    "                set(quality_list), key=quality_list.count\n",
    "            )\n",
    "            site_data[\"number_of_pollutants\"] = len(quality_list)\n",
    "        else:\n",
    "            site_data[\"pollutants_status\"] = \"no_species_data\"\n",
    "            site_data[\"number_of_pollutants\"] = 0\n",
    "\n",
    "        authority_data.append(site_data)\n",
    "    return authority_data\n",
    "\n",
    "\n",
    "def parse_hourly_response(hourly_response : Dict) -> Dict:\n",
    "    \"\"\"Return data indexed by Borough.\"\"\"\n",
    "    data = dict.fromkeys(AUTHORITIES)\n",
    "    for authority in AUTHORITIES:\n",
    "        try:\n",
    "            for entry in hourly_response[\"HourlyAirQualityIndex\"][\"LocalAuthority\"]:\n",
    "                if entry[\"@LocalAuthorityName\"] == authority:\n",
    "\n",
    "                    if isinstance(entry[\"Site\"], dict):\n",
    "                        entry_sites_data = [entry[\"Site\"]]\n",
    "                    else:\n",
    "                        entry_sites_data = entry[\"Site\"]\n",
    "\n",
    "                    data[authority] = parse_site(entry_sites_data)\n",
    "        except Exception as exc: \n",
    "            # catch misformatted or missing data\n",
    "            # print(exc)\n",
    "            data[authority] = {}\n",
    "    return data\n",
    "\n",
    "class LondonAirQualityException(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    hourly_data_raw = request_data(LAQ_HOURLY_URL)\n",
    "except LondonAirQualityException as exc:\n",
    "    print(exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo inner workings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API response lists 33 `LocalAuthority` but only 27 return data, so in applications it is useful to not allow configuration to display info for the boroughs with no data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hourly_data_raw['HourlyAirQualityIndex']['LocalAuthority'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the raw data for a single `LocalAuthority`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@LocalAuthorityCode': '1',\n",
       " '@LocalAuthorityName': 'Barking and Dagenham',\n",
       " '@LaCentreLatitude': '51.538435',\n",
       " '@LaCentreLongitude': '0.11467',\n",
       " '@LaCentreLatitudeWGS84': '6717095.01808',\n",
       " '@LaCentreLongitudeWGS84': '12765.0060093',\n",
       " 'Site': [{'@BulletinDate': '2019-09-26 08:00:00',\n",
       "   '@SiteCode': 'BG1',\n",
       "   '@SiteName': 'Barking and Dagenham - Rush Green',\n",
       "   '@SiteType': 'Suburban',\n",
       "   '@Latitude': '51.563752',\n",
       "   '@Longitude': '0.177891',\n",
       "   '@LatitudeWGS84': '6721627.34498',\n",
       "   '@LongitudeWGS84': '19802.7355367',\n",
       "   '@OwnerID': '1',\n",
       "   'Species': [{'@SpeciesCode': 'NO2',\n",
       "     '@SpeciesDescription': 'Nitrogen Dioxide',\n",
       "     '@AirQualityIndex': '1',\n",
       "     '@AirQualityBand': 'Low',\n",
       "     '@IndexSource': 'Measurement'},\n",
       "    {'@SpeciesCode': 'SO2',\n",
       "     '@SpeciesDescription': 'Sulphur Dioxide',\n",
       "     '@AirQualityIndex': '1',\n",
       "     '@AirQualityBand': 'Low',\n",
       "     '@IndexSource': 'Measurement'}]},\n",
       "  {'@BulletinDate': '2019-09-26 08:00:00',\n",
       "   '@SiteCode': 'BG2',\n",
       "   '@SiteName': 'Barking and Dagenham - Scrattons Farm',\n",
       "   '@SiteType': 'Suburban',\n",
       "   '@Latitude': '51.529389',\n",
       "   '@Longitude': '0.132857',\n",
       "   '@LatitudeWGS84': '6715476.18683',\n",
       "   '@LongitudeWGS84': '14789.5735883',\n",
       "   '@OwnerID': '1',\n",
       "   'Species': [{'@SpeciesCode': 'NO2',\n",
       "     '@SpeciesDescription': 'Nitrogen Dioxide',\n",
       "     '@AirQualityIndex': '1',\n",
       "     '@AirQualityBand': 'Low',\n",
       "     '@IndexSource': 'Measurement'},\n",
       "    {'@SpeciesCode': 'PM10',\n",
       "     '@SpeciesDescription': 'PM10 Particulate',\n",
       "     '@AirQualityIndex': '1',\n",
       "     '@AirQualityBand': 'Low',\n",
       "     '@IndexSource': 'Trigger'}]}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_data_raw['HourlyAirQualityIndex']['LocalAuthority'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse out the sites data for this local authority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'updated': '2019-09-26 08:00:00',\n",
       "  'latitude': '51.563752',\n",
       "  'longitude': '0.177891',\n",
       "  'site_code': 'BG1',\n",
       "  'site_name': 'Rush Green',\n",
       "  'site_type': 'Suburban',\n",
       "  'pollutants': [{'description': 'Nitrogen Dioxide',\n",
       "    'code': 'NO2',\n",
       "    'quality': 'Low',\n",
       "    'index': '1',\n",
       "    'summary': 'NO2 is Low'},\n",
       "   {'description': 'Sulphur Dioxide',\n",
       "    'code': 'SO2',\n",
       "    'quality': 'Low',\n",
       "    'index': '1',\n",
       "    'summary': 'SO2 is Low'}],\n",
       "  'pollutants_status': 'Low',\n",
       "  'number_of_pollutants': 2},\n",
       " {'updated': '2019-09-26 08:00:00',\n",
       "  'latitude': '51.529389',\n",
       "  'longitude': '0.132857',\n",
       "  'site_code': 'BG2',\n",
       "  'site_name': 'Scrattons Farm',\n",
       "  'site_type': 'Suburban',\n",
       "  'pollutants': [{'description': 'Nitrogen Dioxide',\n",
       "    'code': 'NO2',\n",
       "    'quality': 'Low',\n",
       "    'index': '1',\n",
       "    'summary': 'NO2 is Low'},\n",
       "   {'description': 'PM10 Particulate',\n",
       "    'code': 'PM10',\n",
       "    'quality': 'Low',\n",
       "    'index': '1',\n",
       "    'summary': 'PM10 is Low'}],\n",
       "  'pollutants_status': 'Low',\n",
       "  'number_of_pollutants': 2}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites_data = parse_site(hourly_data_raw['HourlyAirQualityIndex']['LocalAuthority'][0]['Site'])\n",
    "sites_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_data = parse_hourly_response(hourly_data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'updated': '2019-09-26 08:00:00',\n",
       "  'latitude': '51.563752',\n",
       "  'longitude': '0.177891',\n",
       "  'site_code': 'BG1',\n",
       "  'site_name': 'Rush Green',\n",
       "  'site_type': 'Suburban',\n",
       "  'pollutants': [{'description': 'Nitrogen Dioxide',\n",
       "    'code': 'NO2',\n",
       "    'quality': 'Low',\n",
       "    'index': '1',\n",
       "    'summary': 'NO2 is Low'},\n",
       "   {'description': 'Sulphur Dioxide',\n",
       "    'code': 'SO2',\n",
       "    'quality': 'Low',\n",
       "    'index': '1',\n",
       "    'summary': 'SO2 is Low'}],\n",
       "  'pollutants_status': 'Low',\n",
       "  'number_of_pollutants': 2},\n",
       " {'updated': '2019-09-26 08:00:00',\n",
       "  'latitude': '51.529389',\n",
       "  'longitude': '0.132857',\n",
       "  'site_code': 'BG2',\n",
       "  'site_name': 'Scrattons Farm',\n",
       "  'site_type': 'Suburban',\n",
       "  'pollutants': [{'description': 'Nitrogen Dioxide',\n",
       "    'code': 'NO2',\n",
       "    'quality': 'Low',\n",
       "    'index': '1',\n",
       "    'summary': 'NO2 is Low'},\n",
       "   {'description': 'PM10 Particulate',\n",
       "    'code': 'PM10',\n",
       "    'quality': 'Low',\n",
       "    'index': '1',\n",
       "    'summary': 'PM10 is Low'}],\n",
       "  'pollutants_status': 'Low',\n",
       "  'number_of_pollutants': 2}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_data['Barking and Dagenham']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe\n",
    "We can also process the data into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hourly_dataframe(hourly_data : Dict) -> pd.DataFrame:\n",
    "    all_data = []\n",
    "    for authority in hourly_data.keys():\n",
    "        for site in hourly_data[authority]:        \n",
    "            for pollutant in site['pollutants']:\n",
    "                try:\n",
    "                    pollutant['borough'] = authority\n",
    "                    pollutant['site_code'] = site['site_code']\n",
    "                    pollutant['site_name'] = site['site_name']\n",
    "                    pollutant['latitude'] = site['latitude']\n",
    "                    pollutant['longitude'] = site['longitude']\n",
    "                    pollutant['updated'] = site['updated']\n",
    "                    all_data.append(pollutant)\n",
    "                except:\n",
    "                    pass\n",
    "    df = pd.DataFrame(all_data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_hourly_dataframe(hourly_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>borough</th>\n",
       "      <th>code</th>\n",
       "      <th>description</th>\n",
       "      <th>index</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>quality</th>\n",
       "      <th>site_code</th>\n",
       "      <th>site_name</th>\n",
       "      <th>summary</th>\n",
       "      <th>updated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barking and Dagenham</td>\n",
       "      <td>NO2</td>\n",
       "      <td>Nitrogen Dioxide</td>\n",
       "      <td>1</td>\n",
       "      <td>51.563752</td>\n",
       "      <td>0.177891</td>\n",
       "      <td>Low</td>\n",
       "      <td>BG1</td>\n",
       "      <td>Rush Green</td>\n",
       "      <td>NO2 is Low</td>\n",
       "      <td>2019-09-26 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barking and Dagenham</td>\n",
       "      <td>SO2</td>\n",
       "      <td>Sulphur Dioxide</td>\n",
       "      <td>1</td>\n",
       "      <td>51.563752</td>\n",
       "      <td>0.177891</td>\n",
       "      <td>Low</td>\n",
       "      <td>BG1</td>\n",
       "      <td>Rush Green</td>\n",
       "      <td>SO2 is Low</td>\n",
       "      <td>2019-09-26 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barking and Dagenham</td>\n",
       "      <td>NO2</td>\n",
       "      <td>Nitrogen Dioxide</td>\n",
       "      <td>1</td>\n",
       "      <td>51.529389</td>\n",
       "      <td>0.132857</td>\n",
       "      <td>Low</td>\n",
       "      <td>BG2</td>\n",
       "      <td>Scrattons Farm</td>\n",
       "      <td>NO2 is Low</td>\n",
       "      <td>2019-09-26 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barking and Dagenham</td>\n",
       "      <td>PM10</td>\n",
       "      <td>PM10 Particulate</td>\n",
       "      <td>1</td>\n",
       "      <td>51.529389</td>\n",
       "      <td>0.132857</td>\n",
       "      <td>Low</td>\n",
       "      <td>BG2</td>\n",
       "      <td>Scrattons Farm</td>\n",
       "      <td>PM10 is Low</td>\n",
       "      <td>2019-09-26 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bexley</td>\n",
       "      <td>NO2</td>\n",
       "      <td>Nitrogen Dioxide</td>\n",
       "      <td>1</td>\n",
       "      <td>51.4946486813055</td>\n",
       "      <td>0.137279111232178</td>\n",
       "      <td>Low</td>\n",
       "      <td>BQ7</td>\n",
       "      <td>Belvedere West</td>\n",
       "      <td>NO2 is Low</td>\n",
       "      <td>2019-09-26 08:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                borough  code       description index          latitude  \\\n",
       "0  Barking and Dagenham   NO2  Nitrogen Dioxide     1         51.563752   \n",
       "1  Barking and Dagenham   SO2   Sulphur Dioxide     1         51.563752   \n",
       "2  Barking and Dagenham   NO2  Nitrogen Dioxide     1         51.529389   \n",
       "3  Barking and Dagenham  PM10  PM10 Particulate     1         51.529389   \n",
       "4                Bexley   NO2  Nitrogen Dioxide     1  51.4946486813055   \n",
       "\n",
       "           longitude quality site_code       site_name      summary  \\\n",
       "0           0.177891     Low       BG1      Rush Green   NO2 is Low   \n",
       "1           0.177891     Low       BG1      Rush Green   SO2 is Low   \n",
       "2           0.132857     Low       BG2  Scrattons Farm   NO2 is Low   \n",
       "3           0.132857     Low       BG2  Scrattons Farm  PM10 is Low   \n",
       "4  0.137279111232178     Low       BQ7  Belvedere West   NO2 is Low   \n",
       "\n",
       "               updated  \n",
       "0  2019-09-26 08:00:00  \n",
       "1  2019-09-26 08:00:00  \n",
       "2  2019-09-26 08:00:00  \n",
       "3  2019-09-26 08:00:00  \n",
       "4  2019-09-26 08:00:00  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Barking and Dagenham' 'Bexley' 'Brent' 'Camden' 'City of London'\n",
      " 'Croydon' 'Ealing' 'Enfield' 'Greenwich' 'Hackney' 'Haringey' 'Harrow'\n",
      " 'Havering' 'Hillingdon' 'Islington' 'Kensington and Chelsea' 'Kingston'\n",
      " 'Lambeth' 'Lewisham' 'Merton' 'Redbridge' 'Richmond' 'Southwark' 'Sutton'\n",
      " 'Tower Hamlets' 'Wandsworth' 'Westminster']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boroughs_with_data = df['borough'].unique()\n",
    "print(boroughs_with_data)\n",
    "len(boroughs_with_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Waltham Forest',\n",
       " 'Newham',\n",
       " 'Hammersmith and Fulham',\n",
       " 'Bromley',\n",
       " 'Hounslow',\n",
       " 'Barnet']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boroughs_without_data = list(set(ALL_AUTHORITIES) - set(boroughs_with_data))\n",
    "boroughs_without_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NO2     77\n",
       "PM10    61\n",
       "PM25    18\n",
       "O3      16\n",
       "SO2      6\n",
       "Name: code, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Low    178\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    156\n",
       "2     22\n",
       "Name: index, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['index'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
